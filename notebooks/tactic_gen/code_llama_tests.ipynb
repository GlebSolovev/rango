{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/coq-modeling/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" \n",
    "\n",
    "from flask import Flask, request\n",
    "from transformers import (LlamaForCausalLM, CodeLlamaTokenizer,\n",
    "                          BitsAndBytesConfig, StoppingCriteriaList)\n",
    "import torch\n",
    "\n",
    "from tactic_gen.lm_example import LmExample \n",
    "from tactic_gen.train_codellama import (collate_input, CONF_NAME, load_config,\n",
    "                                        get_tokenizer)\n",
    "from model_deployment.serve_base_codellama import PeriodStoppingCriteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name, quantization_config=quantization_config\n",
    ")\n",
    "tokenizer = CodeLlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_stopping = PeriodStoppingCriteria.from_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[').',\n",
       " '..',\n",
       " '...',\n",
       " '▁.',\n",
       " '.\"',\n",
       " '`.',\n",
       " '$.',\n",
       " '\".',\n",
       " '».',\n",
       " '.,',\n",
       " '].',\n",
       " '}.',\n",
       " '.)',\n",
       " '▁...',\n",
       " '().',\n",
       " '\").',\n",
       " \"').\",\n",
       " '._',\n",
       " '....',\n",
       " '.”',\n",
       " \"'.\",\n",
       " '}$.',\n",
       " '.:',\n",
       " ')$.',\n",
       " '.}',\n",
       " '▁`.',\n",
       " '_.',\n",
       " '.*',\n",
       " '.]',\n",
       " \".'\",\n",
       " '.).',\n",
       " '/.',\n",
       " '▁..',\n",
       " './',\n",
       " '../',\n",
       " '.[',\n",
       " '.$',\n",
       " ',.',\n",
       " '}).',\n",
       " '.--',\n",
       " '.\\\\',\n",
       " ')).',\n",
       " '▁$.',\n",
       " '”.',\n",
       " '.;',\n",
       " '.~\\\\',\n",
       " '.-',\n",
       " '“.',\n",
       " '.):',\n",
       " '.),',\n",
       " '?.',\n",
       " '▁».',\n",
       " '*.',\n",
       " '........',\n",
       " '².',\n",
       " '▁\".',\n",
       " '...)',\n",
       " '▁./',\n",
       " '(.',\n",
       " '/).',\n",
       " \"▁$('.\",\n",
       " \"('.\",\n",
       " '`).',\n",
       " '▁....',\n",
       " '.~',\n",
       " \"'].\",\n",
       " '()`.',\n",
       " '▁).',\n",
       " '.(',\n",
       " ')`.',\n",
       " '▁(.',\n",
       " '.“',\n",
       " ']).',\n",
       " \"▁'.\",\n",
       " '>.',\n",
       " '%.',\n",
       " '].[',\n",
       " '.»',\n",
       " '▁.=',\n",
       " '...,',\n",
       " '.’',\n",
       " '()).',\n",
       " '\"].',\n",
       " '.__',\n",
       " '(\".',\n",
       " '...]',\n",
       " '▁$(\".',\n",
       " '.`',\n",
       " '...\"',\n",
       " '.\");',\n",
       " '.....',\n",
       " '▁%.',\n",
       " '$).',\n",
       " \"▁'./\",\n",
       " '(...',\n",
       " '.<',\n",
       " '.$$',\n",
       " '.\",',\n",
       " ')..',\n",
       " '▁*.',\n",
       " '=.',\n",
       " '.</',\n",
       " '.@',\n",
       " '!.',\n",
       " '../../',\n",
       " '▁[...]',\n",
       " '.—',\n",
       " '\".$',\n",
       " \"'.$\",\n",
       " ']$.',\n",
       " '▁}).',\n",
       " '.\\r',\n",
       " '.\")',\n",
       " '\\\\.',\n",
       " '})$.',\n",
       " '\\\\}$.',\n",
       " '.](',\n",
       " '.=',\n",
       " '!...',\n",
       " '................',\n",
       " ')».',\n",
       " '{.',\n",
       " '}}$.',\n",
       " '.*;',\n",
       " '.:\\u200a',\n",
       " '__.',\n",
       " ',...,',\n",
       " '}}.',\n",
       " ']`.',\n",
       " '`.`',\n",
       " '%).',\n",
       " '(.*',\n",
       " '»).',\n",
       " '▁%).',\n",
       " '-.',\n",
       " '(...)',\n",
       " '²).',\n",
       " ')}.',\n",
       " '=\".',\n",
       " '.«',\n",
       " '▁...)',\n",
       " '▁../',\n",
       " '\\\\).',\n",
       " '▁\"...',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_tok_vocab = dict((v, k) for k, v in tokenizer.get_vocab().items())\n",
    "[reverse_tok_vocab[i] for i in period_stopping.stop_tok_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = 'Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. <FILL_ME>' \n",
    "test_out = \"\\n    + \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(test_in, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "period_stopping.set_num_periods(input_ids)\n",
    "stopping_list = StoppingCriteriaList([period_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndestruct l as [|h t].\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.generate(\n",
    "    input_ids, \n",
    "    temperature=1,\n",
    "    do_sample=True,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=5, \n",
    "    max_new_tokens=200, \n",
    "    stopping_criteria=stopping_list) \n",
    "single_output = model_output[0].to(\"cpu\")\n",
    "token_output = tokenizer.decode(single_output[input_ids.shape[1]:], skip_special_tokens=True)\n",
    "token_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_stopping.set_num_periods(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_stopping.num_input_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|h t].\\n</s>',\n",
       " '<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|h t]. </s>',\n",
       " \"<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|x l'].\\n</s>\",\n",
       " '<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|x xs].\\n</s>',\n",
       " \"<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|x l']. </s>\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collated_in = collate_input(test_in)\n",
    "prompt = '''def remove_non_ascii(s: str) -> str:\n",
    "    \"\"\" <FILL_ME>\n",
    "    return result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=200)\n",
    "output = output[0].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_output = tokenizer.decode(output[input_ids.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(only_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
