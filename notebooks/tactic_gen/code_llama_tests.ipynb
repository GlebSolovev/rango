{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" \n",
    "\n",
    "from flask import Flask, request\n",
    "from transformers import (LlamaForCausalLM, CodeLlamaTokenizer,\n",
    "                          BitsAndBytesConfig, StoppingCriteriaList)\n",
    "import torch\n",
    "\n",
    "from tactic_gen.lm_example import LmExample \n",
    "from tactic_gen.train_codellama import (collate_input, CONF_NAME, load_config,\n",
    "                                        get_tokenizer)\n",
    "from model_deployment.serve_base_codellama import PeriodStoppingCriteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.90s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name, quantization_config=quantization_config\n",
    ")\n",
    "tokenizer = CodeLlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_stopping = PeriodStoppingCriteria.from_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[').',\n",
       " '..',\n",
       " '...',\n",
       " '▁.',\n",
       " '.\"',\n",
       " '`.',\n",
       " '$.',\n",
       " '\".',\n",
       " '».',\n",
       " '.,',\n",
       " '].',\n",
       " '}.',\n",
       " '.)',\n",
       " '▁...',\n",
       " '().',\n",
       " '\").',\n",
       " \"').\",\n",
       " '._',\n",
       " '....',\n",
       " '.”',\n",
       " \"'.\",\n",
       " '}$.',\n",
       " '.:',\n",
       " ')$.',\n",
       " '.}',\n",
       " '▁`.',\n",
       " '_.',\n",
       " '.*',\n",
       " '.]',\n",
       " \".'\",\n",
       " '.).',\n",
       " '/.',\n",
       " '▁..',\n",
       " './',\n",
       " '../',\n",
       " '.[',\n",
       " '.$',\n",
       " ',.',\n",
       " '}).',\n",
       " '.--',\n",
       " '.\\\\',\n",
       " ')).',\n",
       " '▁$.',\n",
       " '”.',\n",
       " '.;',\n",
       " '.~\\\\',\n",
       " '.-',\n",
       " '“.',\n",
       " '.):',\n",
       " '.),',\n",
       " '?.',\n",
       " '▁».',\n",
       " '*.',\n",
       " '........',\n",
       " '².',\n",
       " '▁\".',\n",
       " '...)',\n",
       " '▁./',\n",
       " '(.',\n",
       " '/).',\n",
       " \"▁$('.\",\n",
       " \"('.\",\n",
       " '`).',\n",
       " '▁....',\n",
       " '.~',\n",
       " \"'].\",\n",
       " '()`.',\n",
       " '▁).',\n",
       " '.(',\n",
       " ')`.',\n",
       " '▁(.',\n",
       " '.“',\n",
       " ']).',\n",
       " \"▁'.\",\n",
       " '>.',\n",
       " '%.',\n",
       " '].[',\n",
       " '.»',\n",
       " '▁.=',\n",
       " '...,',\n",
       " '.’',\n",
       " '()).',\n",
       " '\"].',\n",
       " '.__',\n",
       " '(\".',\n",
       " '...]',\n",
       " '▁$(\".',\n",
       " '.`',\n",
       " '...\"',\n",
       " '.\");',\n",
       " '.....',\n",
       " '▁%.',\n",
       " '$).',\n",
       " \"▁'./\",\n",
       " '(...',\n",
       " '.<',\n",
       " '.$$',\n",
       " '.\",',\n",
       " ')..',\n",
       " '▁*.',\n",
       " '=.',\n",
       " '.</',\n",
       " '.@',\n",
       " '!.',\n",
       " '../../',\n",
       " '▁[...]',\n",
       " '.—',\n",
       " '\".$',\n",
       " \"'.$\",\n",
       " ']$.',\n",
       " '▁}).',\n",
       " '.\\r',\n",
       " '.\")',\n",
       " '\\\\.',\n",
       " '})$.',\n",
       " '\\\\}$.',\n",
       " '.](',\n",
       " '.=',\n",
       " '!...',\n",
       " '................',\n",
       " ')».',\n",
       " '{.',\n",
       " '}}$.',\n",
       " '.*;',\n",
       " '.:\\u200a',\n",
       " '__.',\n",
       " ',...,',\n",
       " '}}.',\n",
       " ']`.',\n",
       " '`.`',\n",
       " '%).',\n",
       " '(.*',\n",
       " '»).',\n",
       " '▁%).',\n",
       " '-.',\n",
       " '(...)',\n",
       " '²).',\n",
       " ')}.',\n",
       " '=\".',\n",
       " '.«',\n",
       " '▁...)',\n",
       " '▁../',\n",
       " '\\\\).',\n",
       " '▁\"...',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_tok_vocab = dict((v, k) for k, v in tokenizer.get_vocab().items())\n",
    "[reverse_tok_vocab[i] for i in period_stopping.stop_tok_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 32007]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = \"<PRE>\" \n",
    "encoded_ids = tokenizer.encode(pad_token)\n",
    "assert len(encoded_ids) == 2\n",
    "assert encoded_ids[0] == tokenizer.bos_token_id\n",
    "\n",
    "tokenizer.pad_token = pad_token\n",
    "tokenizer.pad_token_id = encoded_ids[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = 'Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. <FILL_ME>' \n",
    "test_out = \"\\n    + \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(test_in, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "period_stopping.set_num_periods(input_ids)\n",
    "stopping_list = StoppingCriteriaList([period_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndestruct l as [| l0 l1].'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = model.generate(\n",
    "    input_ids, \n",
    "    temperature=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=200, \n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True,\n",
    "    stopping_criteria=stopping_list,\n",
    "    ) \n",
    "single_output = model_output.sequences[0].to(\"cpu\")\n",
    "token_output = tokenizer.decode(single_output[input_ids.shape[1]:], skip_special_tokens=True)\n",
    "token_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.generation.utils.SampleDecoderOnlyOutput"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\napply exists_min_nonempty in H.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model_output.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndestruct l as [| l0 l1].'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model_output.sequences[0, input_ids.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   -inf,    -inf, 10.8047,  ...,    -inf,    -inf,    -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[  -inf,   -inf, 9.7266,  ...,   -inf,   -inf,   -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sequence_score(input_sequence: torch.LongTensor,\n",
    "                       whole_sequence: torch.LongTensor, \n",
    "                       scores: tuple[torch.FloatTensor],\n",
    "                       stop_criteria: PeriodStoppingCriteria) -> float:\n",
    "    assert len(scores) == int(whole_sequence.shape[0] - input_sequence.shape[0])\n",
    "    sequence_score = 0\n",
    "    start_idx = whole_sequence.shape[0] - len(scores)\n",
    "    stop_criteria.set_num_periods(input_sequence[None, :])\n",
    "    for i in range(len(scores)):\n",
    "        index = whole_sequence[start_idx + i] \n",
    "        score_at_i = scores[i][0, index] - torch.logsumexp(scores[i][0], axis=0)\n",
    "        sequence_score += (score_at_i)\n",
    "        if stop_criteria(whole_sequence[None, :(start_idx + i + 1)], scores):\n",
    "            break\n",
    "    return sequence_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.2211, device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sequence_score(\n",
    "    input_ids[0], \n",
    "    model_output.sequences[0], \n",
    "    model_output.scores, period_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32016])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.scores[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleDecoderOnlyOutput(sequences=tensor([[    1, 11894,  4864, 29918,  1195, 29901, 25345,   313, 29880,   584,\n",
       "           313,  1761, 14033,  8243, 29871,    13,  1678,   313, 29880, 15271,\n",
       "          4263, 29897,  1599,  4864,   298, 29892,  1375, 29898, 29880, 29897,\n",
       "           353,  3834, 29898, 29882,   467,    13, 28116, 29889, 29871,    13,\n",
       "           524,  1883,   301,   379, 29889, 29871,    13,  7854,  1247,   313,\n",
       "          1195, 29898, 29880,  8106]], device='cuda:0'), scores=(tensor([[   -inf,    -inf, 10.8047,  ...,    -inf,    -inf,    -inf]],\n",
       "       device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[  -inf,   -inf, 7.7188,  ...,   -inf,   -inf,   -inf]],\n",
       "       device='cuda:0'), tensor([[  -inf,   -inf, 8.1875,  ...,   -inf,   -inf,   -inf]],\n",
       "       device='cuda:0'), tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'), tensor([[  -inf,   -inf, 7.5156,  ...,   -inf,   -inf,   -inf]],\n",
       "       device='cuda:0'), tensor([[   -inf,    -inf, 10.0156,  ...,    -inf,    -inf,    -inf]],\n",
       "       device='cuda:0'), tensor([[  -inf,   -inf, 9.2188,  ...,   -inf,   -inf,   -inf]],\n",
       "       device='cuda:0')), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   -inf,    -inf, 10.8047,  ...,    -inf,    -inf,    -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[  -inf,   -inf, 7.7188,  ...,   -inf,   -inf,   -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[  -inf,   -inf, 8.1875,  ...,   -inf,   -inf,   -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device='cuda:0'),\n",
       " tensor([[  -inf,   -inf, 7.5156,  ...,   -inf,   -inf,   -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[   -inf,    -inf, 10.0156,  ...,    -inf,    -inf,    -inf]],\n",
       "        device='cuda:0'),\n",
       " tensor([[  -inf,   -inf, 9.2188,  ...,   -inf,   -inf,   -inf]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_stopping.set_num_periods(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_stopping.num_input_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|h t].</s>',\n",
       " \"<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|x l'].</s>\",\n",
       " '<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [|x xs].</s>',\n",
       " '<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [| h t].</s>',\n",
       " \"<s> Lemma exists_min: forall (l : (list nat)), \\n    (l <> nil) -> exists h, min(l) = Some(h).\\nProof. \\nintros l H. \\ndestruct l as [| x l'].</s>\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model_output.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collated_in = collate_input(test_in)\n",
    "prompt = '''def remove_non_ascii(s: str) -> str:\n",
    "    \"\"\" <FILL_ME>\n",
    "    return result\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=200)\n",
    "output = output[0].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_output = tokenizer.decode(output[input_ids.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(only_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
