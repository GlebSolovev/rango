{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/coq-modeling/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "from flask import Flask, request\n",
    "from transformers import (LlamaForCausalLM, CodeLlamaTokenizer,\n",
    "                          BitsAndBytesConfig)\n",
    "import torch\n",
    "\n",
    "from data_management.lm_example import LmExample \n",
    "from tactic_gen.train_codellama import (collate_input, CONF_NAME, load_config,\n",
    "                                        get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.06s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_LOC = \"/home/ubuntu/coq-modeling/models/codellama-7b-basic\"\n",
    "CHECKPOINT_NUM = 1800 \n",
    "\n",
    "model_path = os.path.join(MODEL_LOC, f\"checkpoint-{CHECKPOINT_NUM}\")\n",
    "model_conf = load_config(os.path.join(MODEL_LOC, CONF_NAME))\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_path, quantization_config=quantization_config\n",
    ")\n",
    "tokenizer = get_tokenizer(model_conf) \n",
    "tokenizer.add_eos_token = False # Don't add eos to input during inference\n",
    "max_input_len = model_conf[\"max_input_len\"]\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/coq-modeling/venv/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    }
   ],
   "source": [
    "test_in = \"\"\"\\\n",
    "Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\n",
    "\n",
    "∀ n m : nat, 0 + S n * m = S n * m\"\"\" \n",
    "collated_in = collate_input(tokenizer, max_input_len, test_in)\n",
    "input_ids = tokenizer(collated_in, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=10,\n",
    "    max_new_tokens=200,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8, 6, 7, 6, 5, 4, 8, 6, 7], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_padding_tokens = (output.sequences == tokenizer.pad_token_id).sum(axis=1)\n",
    "output.sequences.shape[1] - input_ids.shape[1] - num_padding_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   13, 29871, 25956,   302,   286, 29889, 29871,     2],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.sequences[1][input_ids.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.generation.utils.BeamSearchDecoderOnlyOutput"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n  intros n m.',\n",
       " '\\n  intros n m. ',\n",
       " 'intros n m. ',\n",
       " '\\n    intros n m.',\n",
       " '\\n  intros. ',\n",
       " '\\n  intros.',\n",
       " 'intros. ',\n",
       " '\\n    intros n m. ',\n",
       " 'reflexivity. ',\n",
       " '\\nintros n m.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output.sequences[:, input_ids.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n  intros n m.</s>▁<PRE>', tensor(-0.0225, device='cuda:0'))\n",
      "('\\n  intros n m. </s>', tensor(-0.0266, device='cuda:0'))\n",
      "('intros n m. </s>▁<PRE>▁<PRE>', tensor(-0.0381, device='cuda:0'))\n",
      "('\\n    intros n m.</s>▁<PRE>', tensor(-0.0473, device='cuda:0'))\n",
      "('\\n  intros. </s>▁<PRE>▁<PRE>', tensor(-0.0502, device='cuda:0'))\n",
      "('\\n  intros.</s>▁<PRE>▁<PRE>▁<PRE>', tensor(-0.0505, device='cuda:0'))\n",
      "('intros. </s>▁<PRE>▁<PRE>▁<PRE>▁<PRE>', tensor(-0.0529, device='cuda:0'))\n",
      "('\\n    intros n m. </s>', tensor(-0.0546, device='cuda:0'))\n",
      "('reflexivity. </s>▁<PRE>▁<PRE>', tensor(-0.0596, device='cuda:0'))\n",
      "('\\nintros n m.</s>▁<PRE>', tensor(-0.0643, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "sequences = output.sequences\n",
    "sequences_scores = output.sequences_scores\n",
    "for sequence, score in zip(sequences, sequences_scores):\n",
    "    print((tokenizer.decode(sequence[input_ids.shape[1]:], skip_special_tokens=False), score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchDecoderOnlyOutput(sequences=tensor([[    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889,     2,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,   524,  1883,   302,   286, 29889, 29871,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,  1678, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 20220,  2298, 29889, 29871,     2,\n",
       "             2]], device='cuda:0'), sequences_scores=tensor([-0.0264, -0.0352, -0.0445, -0.0533, -0.0607, -0.0634, -0.0695, -0.0702,\n",
       "        -0.0722, -0.0742], device='cuda:0'), scores=(tensor([[-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        ...,\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577]],\n",
       "       device='cuda:0'), tensor([[-16.2049, -20.7909,  -7.4159,  ..., -14.8990, -13.2792, -15.3717],\n",
       "        [-19.4558, -20.5789,  -4.5457,  ..., -16.8198, -17.0659, -17.9211],\n",
       "        [-20.5151, -24.3491, -11.3335,  ..., -20.2546, -18.9214, -20.8530],\n",
       "        ...,\n",
       "        [-25.2098, -24.3875, -10.0008,  ..., -24.1531, -21.9400, -22.8440],\n",
       "        [-24.5632, -25.1726,  -7.6961,  ..., -20.4256, -18.5867, -20.0496],\n",
       "        [-24.8365, -25.4459, -13.8365,  ..., -20.8380, -18.9830, -20.7667]],\n",
       "       device='cuda:0'), tensor([[-17.8605, -20.5812,  -6.2179,  ..., -15.1036, -15.2176, -15.8575],\n",
       "        [-20.9339, -24.5803, -11.7014,  ..., -20.5010, -19.1961, -21.1526],\n",
       "        [-17.5884, -20.4731,  -7.2036,  ..., -14.8584, -14.9861, -15.1826],\n",
       "        ...,\n",
       "        [-20.3710, -20.0585,  -5.4433,  ..., -19.5995, -15.7421, -16.9439],\n",
       "        [-19.8429, -19.5929,  -5.4484,  ..., -19.8722, -16.1720, -17.2623],\n",
       "        [-16.9641, -19.9905,  -7.2835,  ..., -14.7600, -14.5156, -14.8791]],\n",
       "       device='cuda:0'), tensor([[-20.2881, -20.0440,  -5.5225,  ..., -20.2783, -16.6709, -17.6517],\n",
       "        [-20.1257, -19.3893,  -5.6257,  ..., -20.3483, -16.6833, -17.2773],\n",
       "        [-19.7866, -22.0952,  -7.1889,  ..., -15.0586, -15.9135, -14.8051],\n",
       "        ...,\n",
       "        [-21.1521, -20.2204,  -5.6638,  ..., -20.1872, -15.9568, -17.8618],\n",
       "        [-16.9696, -19.3524,  -4.6415,  ..., -14.9755, -15.0023, -15.5814],\n",
       "        [-21.0157, -20.4923,  -5.4083,  ..., -19.8849, -16.0030, -17.2936]],\n",
       "       device='cuda:0'), tensor([[-21.8491, -20.7573,  -5.5873,  ..., -20.1010, -15.5873, -18.0767],\n",
       "        [-22.3323, -19.7429,  -1.3537,  ..., -18.7772, -18.2810, -18.7711],\n",
       "        [-21.2226, -20.1503,  -5.5917,  ..., -19.9784, -15.7226, -17.7076],\n",
       "        ...,\n",
       "        [-19.7414, -22.1516,  -6.9485,  ..., -18.3801, -16.8508, -17.4660],\n",
       "        [-20.9292, -20.0854,  -6.1694,  ..., -19.6792, -16.5371, -18.1328],\n",
       "        [-20.0020, -22.0997,  -7.1192,  ..., -18.0245, -16.8429, -16.9234]],\n",
       "       device='cuda:0'), tensor([[-2.2181e+01, -2.0531e+01, -6.2786e+00,  ..., -2.0128e+01,\n",
       "         -1.7227e+01, -1.7959e+01],\n",
       "        [-2.7218e+01, -2.3895e+01, -8.6115e-04,  ..., -2.4513e+01,\n",
       "         -2.5018e+01, -2.6190e+01],\n",
       "        [-2.1836e+01, -2.0666e+01, -6.5055e+00,  ..., -2.0109e+01,\n",
       "         -1.7419e+01, -1.8045e+01],\n",
       "        ...,\n",
       "        [-2.3692e+01, -2.0684e+01, -4.8673e-01,  ..., -2.0376e+01,\n",
       "         -2.0961e+01, -2.1636e+01],\n",
       "        [-2.2985e+01, -2.0811e+01, -1.0160e+00,  ..., -1.8766e+01,\n",
       "         -1.8370e+01, -1.9378e+01],\n",
       "        [-2.3298e+01, -2.0915e+01, -9.6617e-01,  ..., -1.9531e+01,\n",
       "         -1.9013e+01, -1.9938e+01]], device='cuda:0'), tensor([[-2.3219e+01, -2.0116e+01, -1.0261e+00,  ..., -1.9723e+01,\n",
       "         -1.8911e+01, -1.9851e+01],\n",
       "        [-1.9737e+01, -1.9855e+01, -4.8663e+00,  ..., -1.4910e+01,\n",
       "         -1.4094e+01, -1.3441e+01],\n",
       "        [-2.2712e+01, -1.9727e+01, -1.0676e+00,  ..., -1.9234e+01,\n",
       "         -1.8275e+01, -1.9094e+01],\n",
       "        ...,\n",
       "        [-2.7919e+01, -2.5277e+01, -7.0547e-04,  ..., -2.4350e+01,\n",
       "         -2.5613e+01, -2.6025e+01],\n",
       "        [-2.7456e+01, -2.4169e+01, -8.3364e-04,  ..., -2.4156e+01,\n",
       "         -2.4911e+01, -2.6285e+01],\n",
       "        [-2.7772e+01, -2.4431e+01, -4.8935e-04,  ..., -2.4742e+01,\n",
       "         -2.5356e+01, -2.6616e+01]], device='cuda:0'), tensor([[-2.7983e+01, -2.4412e+01, -9.1249e-04,  ..., -2.4877e+01,\n",
       "         -2.5318e+01, -2.6956e+01],\n",
       "        [-2.8243e+01, -2.4903e+01, -5.3618e-04,  ..., -2.5672e+01,\n",
       "         -2.6074e+01, -2.7558e+01],\n",
       "        [-2.3694e+01, -2.3323e+01, -7.1006e+00,  ..., -2.0232e+01,\n",
       "         -1.7345e+01, -1.7899e+01],\n",
       "        ...,\n",
       "        [-2.3395e+01, -2.3067e+01, -7.1056e+00,  ..., -2.0290e+01,\n",
       "         -1.7413e+01, -1.7654e+01],\n",
       "        [-2.2952e+01, -2.3354e+01, -7.8933e+00,  ..., -1.7707e+01,\n",
       "         -1.7528e+01, -1.7645e+01],\n",
       "        [-2.1686e+01, -2.2389e+01, -5.5491e+00,  ..., -1.7815e+01,\n",
       "         -1.6467e+01, -1.7253e+01]], device='cuda:0'), tensor([[-20.7668, -22.1340,  -6.7746,  ..., -18.1003, -17.2526, -17.0278],\n",
       "        [-24.3028, -23.4552, -10.0255,  ..., -23.0079, -20.7352, -20.4494],\n",
       "        [-20.3330, -21.2783,  -7.2217,  ..., -17.7578, -17.7615, -17.1542],\n",
       "        ...,\n",
       "        [-20.8918, -22.2551,  -6.7863,  ..., -18.2844, -17.5314, -17.2582],\n",
       "        [-19.7013, -20.9943,  -6.3380,  ..., -15.6056, -14.7599, -13.7814],\n",
       "        [-25.0319, -21.4028,  -0.6335,  ..., -20.6322, -20.5822, -21.0086]],\n",
       "       device='cuda:0')), beam_indices=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  2,  2,  2,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  2,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  2,  3,  7,  4,  4,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  2,  5,  5,  3,  4,  3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  2,  3,  5,  7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
       "       device='cuda:0'), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\\n\\n∀ n m : nat, 0 + S n * m = S n * m\\n<TACTIC>\\n\\n  intros n m. </s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\\n\\n∀ n m : nat, 0 + S n * m = S n * m\\n<TACTIC>\\n\\n  intros n m.</s></s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         ...,\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-16.2049, -20.7909,  -7.4159,  ..., -14.8990, -13.2792, -15.3717],\n",
       "         [-19.4558, -20.5789,  -4.5457,  ..., -16.8198, -17.0659, -17.9211],\n",
       "         [-20.5151, -24.3491, -11.3335,  ..., -20.2546, -18.9214, -20.8530],\n",
       "         ...,\n",
       "         [-25.2098, -24.3875, -10.0008,  ..., -24.1531, -21.9400, -22.8440],\n",
       "         [-24.5632, -25.1726,  -7.6961,  ..., -20.4256, -18.5867, -20.0496],\n",
       "         [-24.8365, -25.4459, -13.8365,  ..., -20.8380, -18.9830, -20.7667]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-17.8605, -20.5812,  -6.2179,  ..., -15.1036, -15.2176, -15.8575],\n",
       "         [-20.9339, -24.5803, -11.7014,  ..., -20.5010, -19.1961, -21.1526],\n",
       "         [-17.5884, -20.4731,  -7.2036,  ..., -14.8584, -14.9861, -15.1826],\n",
       "         ...,\n",
       "         [-20.3710, -20.0585,  -5.4433,  ..., -19.5995, -15.7421, -16.9439],\n",
       "         [-19.8429, -19.5929,  -5.4484,  ..., -19.8722, -16.1720, -17.2623],\n",
       "         [-16.9641, -19.9905,  -7.2835,  ..., -14.7600, -14.5156, -14.8791]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-20.2881, -20.0440,  -5.5225,  ..., -20.2783, -16.6709, -17.6517],\n",
       "         [-20.1257, -19.3893,  -5.6257,  ..., -20.3483, -16.6833, -17.2773],\n",
       "         [-19.7866, -22.0952,  -7.1889,  ..., -15.0586, -15.9135, -14.8051],\n",
       "         ...,\n",
       "         [-21.1521, -20.2204,  -5.6638,  ..., -20.1872, -15.9568, -17.8618],\n",
       "         [-16.9696, -19.3524,  -4.6415,  ..., -14.9755, -15.0023, -15.5814],\n",
       "         [-21.0157, -20.4923,  -5.4083,  ..., -19.8849, -16.0030, -17.2936]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-21.8491, -20.7573,  -5.5873,  ..., -20.1010, -15.5873, -18.0767],\n",
       "         [-22.3323, -19.7429,  -1.3537,  ..., -18.7772, -18.2810, -18.7711],\n",
       "         [-21.2226, -20.1503,  -5.5917,  ..., -19.9784, -15.7226, -17.7076],\n",
       "         ...,\n",
       "         [-19.7414, -22.1516,  -6.9485,  ..., -18.3801, -16.8508, -17.4660],\n",
       "         [-20.9292, -20.0854,  -6.1694,  ..., -19.6792, -16.5371, -18.1328],\n",
       "         [-20.0020, -22.0997,  -7.1192,  ..., -18.0245, -16.8429, -16.9234]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-2.2181e+01, -2.0531e+01, -6.2786e+00,  ..., -2.0128e+01,\n",
       "          -1.7227e+01, -1.7959e+01],\n",
       "         [-2.7218e+01, -2.3895e+01, -8.6115e-04,  ..., -2.4513e+01,\n",
       "          -2.5018e+01, -2.6190e+01],\n",
       "         [-2.1836e+01, -2.0666e+01, -6.5055e+00,  ..., -2.0109e+01,\n",
       "          -1.7419e+01, -1.8045e+01],\n",
       "         ...,\n",
       "         [-2.3692e+01, -2.0684e+01, -4.8673e-01,  ..., -2.0376e+01,\n",
       "          -2.0961e+01, -2.1636e+01],\n",
       "         [-2.2985e+01, -2.0811e+01, -1.0160e+00,  ..., -1.8766e+01,\n",
       "          -1.8370e+01, -1.9378e+01],\n",
       "         [-2.3298e+01, -2.0915e+01, -9.6617e-01,  ..., -1.9531e+01,\n",
       "          -1.9013e+01, -1.9938e+01]], device='cuda:0'),\n",
       " tensor([[-2.3219e+01, -2.0116e+01, -1.0261e+00,  ..., -1.9723e+01,\n",
       "          -1.8911e+01, -1.9851e+01],\n",
       "         [-1.9737e+01, -1.9855e+01, -4.8663e+00,  ..., -1.4910e+01,\n",
       "          -1.4094e+01, -1.3441e+01],\n",
       "         [-2.2712e+01, -1.9727e+01, -1.0676e+00,  ..., -1.9234e+01,\n",
       "          -1.8275e+01, -1.9094e+01],\n",
       "         ...,\n",
       "         [-2.7919e+01, -2.5277e+01, -7.0547e-04,  ..., -2.4350e+01,\n",
       "          -2.5613e+01, -2.6025e+01],\n",
       "         [-2.7456e+01, -2.4169e+01, -8.3364e-04,  ..., -2.4156e+01,\n",
       "          -2.4911e+01, -2.6285e+01],\n",
       "         [-2.7772e+01, -2.4431e+01, -4.8935e-04,  ..., -2.4742e+01,\n",
       "          -2.5356e+01, -2.6616e+01]], device='cuda:0'),\n",
       " tensor([[-2.7983e+01, -2.4412e+01, -9.1249e-04,  ..., -2.4877e+01,\n",
       "          -2.5318e+01, -2.6956e+01],\n",
       "         [-2.8243e+01, -2.4903e+01, -5.3618e-04,  ..., -2.5672e+01,\n",
       "          -2.6074e+01, -2.7558e+01],\n",
       "         [-2.3694e+01, -2.3323e+01, -7.1006e+00,  ..., -2.0232e+01,\n",
       "          -1.7345e+01, -1.7899e+01],\n",
       "         ...,\n",
       "         [-2.3395e+01, -2.3067e+01, -7.1056e+00,  ..., -2.0290e+01,\n",
       "          -1.7413e+01, -1.7654e+01],\n",
       "         [-2.2952e+01, -2.3354e+01, -7.8933e+00,  ..., -1.7707e+01,\n",
       "          -1.7528e+01, -1.7645e+01],\n",
       "         [-2.1686e+01, -2.2389e+01, -5.5491e+00,  ..., -1.7815e+01,\n",
       "          -1.6467e+01, -1.7253e+01]], device='cuda:0'),\n",
       " tensor([[-20.7668, -22.1340,  -6.7746,  ..., -18.1003, -17.2526, -17.0278],\n",
       "         [-24.3028, -23.4552, -10.0255,  ..., -23.0079, -20.7352, -20.4494],\n",
       "         [-20.3330, -21.2783,  -7.2217,  ..., -17.7578, -17.7615, -17.1542],\n",
       "         ...,\n",
       "         [-20.8918, -22.2551,  -6.7863,  ..., -18.2844, -17.5314, -17.2582],\n",
       "         [-19.7013, -20.9943,  -6.3380,  ..., -15.6056, -14.7599, -13.7814],\n",
       "         [-25.0319, -21.4028,  -0.6335,  ..., -20.6322, -20.5822, -21.0086]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
