{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/coq-modeling/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "from flask import Flask, request\n",
    "from transformers import (LlamaForCausalLM, CodeLlamaTokenizer,\n",
    "                          BitsAndBytesConfig)\n",
    "import torch\n",
    "\n",
    "from data_management.lm_example import LmExample \n",
    "from tactic_gen.train_codellama import (collate_input, CONF_NAME, load_config,\n",
    "                                        get_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.06s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_LOC = \"/home/ubuntu/coq-modeling/models/codellama-7b-basic\"\n",
    "CHECKPOINT_NUM = 1800 \n",
    "\n",
    "model_path = os.path.join(MODEL_LOC, f\"checkpoint-{CHECKPOINT_NUM}\")\n",
    "model_conf = load_config(os.path.join(MODEL_LOC, CONF_NAME))\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_path, quantization_config=quantization_config\n",
    ")\n",
    "tokenizer = get_tokenizer(model_conf) \n",
    "tokenizer.add_eos_token = False # Don't add eos to input during inference\n",
    "max_input_len = model_conf[\"max_input_len\"]\n",
    "device = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['tokennizer'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m collated_in \u001b[39m=\u001b[39m collate_input(tokenizer, max_input_len, test_in)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer(collated_in, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     input_ids,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     num_beams\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     output_scores\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     return_dict_in_generate\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     tokennizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beast.ucsd.edu/home/ubuntu/coq-modeling/notebooks/tactic_gen/query_finetuned.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/coq-modeling/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/coq-modeling/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1429\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m model_kwargs \u001b[39m=\u001b[39m generation_config\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# All unused kwargs must be model kwargs\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m generation_config\u001b[39m.\u001b[39mvalidate()\n\u001b[0;32m-> 1429\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_model_kwargs(model_kwargs\u001b[39m.\u001b[39;49mcopy())\n\u001b[1;32m   1431\u001b[0m \u001b[39m# 2. Set generation parameters if not already defined\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m logits_processor \u001b[39m=\u001b[39m logits_processor \u001b[39mif\u001b[39;00m logits_processor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m LogitsProcessorList()\n",
      "File \u001b[0;32m~/coq-modeling/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1249\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_kwargs\u001b[0;34m(self, model_kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         unused_model_args\u001b[39m.\u001b[39mappend(key)\n\u001b[1;32m   1248\u001b[0m \u001b[39mif\u001b[39;00m unused_model_args:\n\u001b[0;32m-> 1249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following `model_kwargs` are not used by the model: \u001b[39m\u001b[39m{\u001b[39;00munused_model_args\u001b[39m}\u001b[39;00m\u001b[39m (note: typos in the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m generate arguments will also show up in this list)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1252\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The following `model_kwargs` are not used by the model: ['tokennizer'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "test_in = \"\"\"\\\n",
    "Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\n",
    "\n",
    "∀ n m : nat, 0 + S n * m = S n * m\"\"\" \n",
    "collated_in = collate_input(tokenizer, max_input_len, test_in)\n",
    "input_ids = tokenizer(collated_in, return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    num_beams=10,\n",
    "    num_return_sequences=10,\n",
    "    max_new_tokens=200,\n",
    "    output_scores=True,\n",
    "    return_dict_in_generate=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchDecoderOnlyOutput(sequences=tensor([[    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13, 25956,   302,   286, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13, 25956, 29889, 29871,     2,     2,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,  1678, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13, 25956,   302,   286, 29889,     2,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889,     2,     2,     2,\n",
       "             2]], device='cuda:0'), sequences_scores=tensor([-0.0236, -0.0251, -0.0316, -0.0350, -0.0460, -0.0544, -0.0620, -0.0632,\n",
       "        -0.0639, -0.0656], device='cuda:0'), scores=(tensor([[-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166],\n",
       "        [-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166],\n",
       "        [-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166],\n",
       "        ...,\n",
       "        [-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166],\n",
       "        [-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166],\n",
       "        [-19.9385, -23.2724, -10.9443,  ..., -16.7504, -16.6024, -16.3166]],\n",
       "       device='cuda:0'), tensor([[-16.5946, -21.4310, -10.5365,  ..., -15.7933, -14.4759, -16.7115],\n",
       "        [-20.8372, -21.5930,  -8.0872,  ..., -20.5266, -17.3870, -18.3757],\n",
       "        [-20.3953, -22.1355,  -8.0007,  ..., -17.9353, -18.7794, -19.5061],\n",
       "        ...,\n",
       "        [-24.8553, -26.7186, -10.8670,  ..., -21.7049, -17.8778, -18.9176],\n",
       "        [-22.7489, -25.9950, -11.7450,  ..., -17.8723, -18.3844, -17.8128],\n",
       "        [-23.7672, -27.6188, -12.1266,  ..., -19.8365, -19.3434, -18.4048]],\n",
       "       device='cuda:0'), tensor([[-20.0254, -23.9551, -10.8613,  ..., -17.4922, -17.7607, -18.6025],\n",
       "        [-23.0013, -22.7709,  -9.1263,  ..., -20.7357, -16.2465, -18.4803],\n",
       "        [-22.4166, -20.4395,  -2.8169,  ..., -19.3929, -19.0928, -19.4898],\n",
       "        ...,\n",
       "        [-21.4689, -21.9963,  -7.7580,  ..., -20.3556, -16.5070, -18.1230],\n",
       "        [-21.8430, -22.3157,  -9.0266,  ..., -17.9221, -18.1741, -17.8879],\n",
       "        [-28.9494, -28.3986, -14.5080,  ..., -26.9435, -24.1354, -25.4093]],\n",
       "       device='cuda:0'), tensor([[-2.1418e+01, -2.2115e+01, -7.8904e+00,  ..., -2.0787e+01,\n",
       "         -1.7621e+01, -1.8892e+01],\n",
       "        [-2.4280e+01, -2.3311e+01, -9.9519e+00,  ..., -2.0942e+01,\n",
       "         -1.8278e+01, -1.9017e+01],\n",
       "        [-2.6292e+01, -2.3059e+01, -1.6302e-03,  ..., -2.4394e+01,\n",
       "         -2.4619e+01, -2.6162e+01],\n",
       "        ...,\n",
       "        [-2.3010e+01, -2.2471e+01, -8.6625e+00,  ..., -2.0293e+01,\n",
       "         -1.5940e+01, -1.8268e+01],\n",
       "        [-2.2523e+01, -2.2781e+01, -7.8394e+00,  ..., -2.0933e+01,\n",
       "         -1.7266e+01, -1.8835e+01],\n",
       "        [-2.2053e+01, -1.9434e+01, -1.5060e+00,  ..., -1.9349e+01,\n",
       "         -1.9041e+01, -1.9654e+01]], device='cuda:0'), tensor([[-2.3142e+01, -2.2958e+01, -8.8491e+00,  ..., -2.0689e+01,\n",
       "         -1.6538e+01, -1.8512e+01],\n",
       "        [-2.2809e+01, -2.0600e+01, -2.6543e+00,  ..., -2.0270e+01,\n",
       "         -1.9237e+01, -2.0182e+01],\n",
       "        [-2.2170e+01, -1.9673e+01, -1.5181e+00,  ..., -1.9437e+01,\n",
       "         -1.9058e+01, -1.9814e+01],\n",
       "        ...,\n",
       "        [-2.7755e+01, -2.4368e+01, -2.9798e-04,  ..., -2.5064e+01,\n",
       "         -2.5573e+01, -2.7272e+01],\n",
       "        [-2.4172e+01, -2.2906e+01, -9.0622e+00,  ..., -2.0685e+01,\n",
       "         -1.7792e+01, -1.8836e+01],\n",
       "        [-2.4607e+01, -2.4904e+01, -1.0557e+01,  ..., -2.1257e+01,\n",
       "         -1.9204e+01, -1.9564e+01]], device='cuda:0'), tensor([[-2.4284e+01, -2.3479e+01, -9.7563e+00,  ..., -2.1209e+01,\n",
       "         -1.8588e+01, -1.9162e+01],\n",
       "        [-2.7237e+01, -2.3614e+01, -7.5145e-04,  ..., -2.4978e+01,\n",
       "         -2.5264e+01, -2.7066e+01],\n",
       "        [-2.6569e+01, -2.2870e+01, -9.2797e-04,  ..., -2.4831e+01,\n",
       "         -2.5155e+01, -2.6798e+01],\n",
       "        ...,\n",
       "        [-2.2327e+01, -1.9699e+01, -1.4695e+00,  ..., -1.9971e+01,\n",
       "         -1.8976e+01, -2.0147e+01],\n",
       "        [-2.3280e+01, -2.0831e+01, -6.7091e-01,  ..., -2.0160e+01,\n",
       "         -1.9552e+01, -2.0719e+01],\n",
       "        [-2.5796e+01, -2.2317e+01, -1.0745e-03,  ..., -2.4595e+01,\n",
       "         -2.4884e+01, -2.6376e+01]], device='cuda:0'), tensor([[-22.7391, -19.8875,  -1.1502,  ..., -20.5089, -19.5028, -20.9112],\n",
       "        [-21.7567, -19.1029,  -0.9589,  ..., -19.5995, -18.6473, -19.8829],\n",
       "        [-22.1567, -19.2251,  -0.8657,  ..., -20.0066, -19.0015, -20.5159],\n",
       "        ...,\n",
       "        [-20.4396, -22.7364,  -9.5060,  ..., -15.1471, -14.2897, -13.7970],\n",
       "        [-19.1003, -22.4362, -10.1628,  ..., -15.5324, -13.6887, -14.1057],\n",
       "        [-20.5156, -22.2695,  -8.9687,  ..., -15.1716, -14.4653, -13.4844]],\n",
       "       device='cuda:0'), tensor([[-2.7635e+01, -2.3729e+01, -4.2894e-04,  ..., -2.5438e+01,\n",
       "         -2.5821e+01, -2.7909e+01],\n",
       "        [-2.6576e+01, -2.2911e+01, -5.8098e-04,  ..., -2.4862e+01,\n",
       "         -2.5211e+01, -2.6947e+01],\n",
       "        [-2.7446e+01, -2.3422e+01, -3.7389e-04,  ..., -2.5305e+01,\n",
       "         -2.5656e+01, -2.7778e+01],\n",
       "        ...,\n",
       "        [-2.4754e+01, -2.5644e+01, -1.0894e+01,  ..., -2.1470e+01,\n",
       "         -1.8322e+01, -1.9304e+01],\n",
       "        [-2.6231e+01, -2.7981e+01, -1.2106e+01,  ..., -2.2609e+01,\n",
       "         -2.0183e+01, -2.3415e+01],\n",
       "        [-2.4846e+01, -2.5581e+01, -1.0385e+01,  ..., -2.1516e+01,\n",
       "         -1.8172e+01, -1.9336e+01]], device='cuda:0'), tensor([[-2.7236e+01, -2.3339e+01, -6.7188e-04,  ..., -2.5138e+01,\n",
       "         -2.5535e+01, -2.7667e+01],\n",
       "        [-2.1259e+01, -2.3821e+01, -1.0595e+01,  ..., -1.5773e+01,\n",
       "         -1.4949e+01, -1.3808e+01],\n",
       "        [-2.4539e+01, -2.0663e+01, -4.8090e-01,  ..., -2.1745e+01,\n",
       "         -2.1070e+01, -2.2023e+01],\n",
       "        ...,\n",
       "        [-2.4933e+01, -2.1027e+01, -3.9238e-01,  ..., -2.2018e+01,\n",
       "         -2.1441e+01, -2.2591e+01],\n",
       "        [-2.6172e+01, -2.6817e+01, -1.3575e+01,  ..., -2.4028e+01,\n",
       "         -2.1757e+01, -2.1630e+01],\n",
       "        [-2.1022e+01, -2.3319e+01, -1.0866e+01,  ..., -1.7852e+01,\n",
       "         -1.7861e+01, -1.7257e+01]], device='cuda:0')), beam_indices=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  3,  3,  3,  3,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  3,  3,  3,  3,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  4,  4,  4,  4,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
       "       device='cuda:0'), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n  intros n m. ', tensor(-0.0236, device='cuda:0'))\n",
      "('intros n m. ', tensor(-0.0251, device='cuda:0'))\n",
      "('intros. ', tensor(-0.0316, device='cuda:0'))\n",
      "('\\n  intros n m.', tensor(-0.0350, device='cuda:0'))\n",
      "('\\n  intros. ', tensor(-0.0460, device='cuda:0'))\n",
      "('\\nintros n m. ', tensor(-0.0544, device='cuda:0'))\n",
      "('\\nintros n m.', tensor(-0.0620, device='cuda:0'))\n",
      "('\\n    intros n m. ', tensor(-0.0632, device='cuda:0'))\n",
      "('intros n m.', tensor(-0.0639, device='cuda:0'))\n",
      "('\\n  intros.', tensor(-0.0656, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "sequences = output.sequences\n",
    "sequences_scores = output.sequences_scores\n",
    "for sequence, score in zip(sequences, sequences_scores):\n",
    "    print((tokenizer.decode(sequence[input_ids.shape[1]:], skip_special_tokens=True), score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchDecoderOnlyOutput(sequences=tensor([[    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 25956, 29889,     2,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883,   302,   286, 29889,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,   524,  1883,   302,   286, 29889, 29871,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,   524,  1883, 29889, 29871,     2,     2,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13,  1678, 25956,   302,   286, 29889, 29871,\n",
       "             2],\n",
       "        [    1, 10244,  1773, 29918, 29900, 29918, 11242,   584, 29871, 30315,\n",
       "           302,   286,   584, 14033, 29892, 29871, 29900,   718,   313, 29903,\n",
       "           302,   334,   286, 29897,   353,   317,   302,   334,   286, 19423,\n",
       "          4690, 29924, 29899,  1660, 29925, 29958,    13,    13, 30315,   302,\n",
       "           286,   584, 14033, 29892, 29871, 29900,   718,   317,   302,   334,\n",
       "           286,   353,   317,   302,   334,   286,    13, 29966,  6040,  1783,\n",
       "          2965, 29958,    13,    13, 29871, 20220,  2298, 29889, 29871,     2,\n",
       "             2]], device='cuda:0'), sequences_scores=tensor([-0.0264, -0.0352, -0.0445, -0.0533, -0.0607, -0.0634, -0.0695, -0.0702,\n",
       "        -0.0722, -0.0742], device='cuda:0'), scores=(tensor([[-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        ...,\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "        [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577]],\n",
       "       device='cuda:0'), tensor([[-16.2049, -20.7909,  -7.4159,  ..., -14.8990, -13.2792, -15.3717],\n",
       "        [-19.4558, -20.5789,  -4.5457,  ..., -16.8198, -17.0659, -17.9211],\n",
       "        [-20.5151, -24.3491, -11.3335,  ..., -20.2546, -18.9214, -20.8530],\n",
       "        ...,\n",
       "        [-25.2098, -24.3875, -10.0008,  ..., -24.1531, -21.9400, -22.8440],\n",
       "        [-24.5632, -25.1726,  -7.6961,  ..., -20.4256, -18.5867, -20.0496],\n",
       "        [-24.8365, -25.4459, -13.8365,  ..., -20.8380, -18.9830, -20.7667]],\n",
       "       device='cuda:0'), tensor([[-17.8605, -20.5812,  -6.2179,  ..., -15.1036, -15.2176, -15.8575],\n",
       "        [-20.9339, -24.5803, -11.7014,  ..., -20.5010, -19.1961, -21.1526],\n",
       "        [-17.5884, -20.4731,  -7.2036,  ..., -14.8584, -14.9861, -15.1826],\n",
       "        ...,\n",
       "        [-20.3710, -20.0585,  -5.4433,  ..., -19.5995, -15.7421, -16.9439],\n",
       "        [-19.8429, -19.5929,  -5.4484,  ..., -19.8722, -16.1720, -17.2623],\n",
       "        [-16.9641, -19.9905,  -7.2835,  ..., -14.7600, -14.5156, -14.8791]],\n",
       "       device='cuda:0'), tensor([[-20.2881, -20.0440,  -5.5225,  ..., -20.2783, -16.6709, -17.6517],\n",
       "        [-20.1257, -19.3893,  -5.6257,  ..., -20.3483, -16.6833, -17.2773],\n",
       "        [-19.7866, -22.0952,  -7.1889,  ..., -15.0586, -15.9135, -14.8051],\n",
       "        ...,\n",
       "        [-21.1521, -20.2204,  -5.6638,  ..., -20.1872, -15.9568, -17.8618],\n",
       "        [-16.9696, -19.3524,  -4.6415,  ..., -14.9755, -15.0023, -15.5814],\n",
       "        [-21.0157, -20.4923,  -5.4083,  ..., -19.8849, -16.0030, -17.2936]],\n",
       "       device='cuda:0'), tensor([[-21.8491, -20.7573,  -5.5873,  ..., -20.1010, -15.5873, -18.0767],\n",
       "        [-22.3323, -19.7429,  -1.3537,  ..., -18.7772, -18.2810, -18.7711],\n",
       "        [-21.2226, -20.1503,  -5.5917,  ..., -19.9784, -15.7226, -17.7076],\n",
       "        ...,\n",
       "        [-19.7414, -22.1516,  -6.9485,  ..., -18.3801, -16.8508, -17.4660],\n",
       "        [-20.9292, -20.0854,  -6.1694,  ..., -19.6792, -16.5371, -18.1328],\n",
       "        [-20.0020, -22.0997,  -7.1192,  ..., -18.0245, -16.8429, -16.9234]],\n",
       "       device='cuda:0'), tensor([[-2.2181e+01, -2.0531e+01, -6.2786e+00,  ..., -2.0128e+01,\n",
       "         -1.7227e+01, -1.7959e+01],\n",
       "        [-2.7218e+01, -2.3895e+01, -8.6115e-04,  ..., -2.4513e+01,\n",
       "         -2.5018e+01, -2.6190e+01],\n",
       "        [-2.1836e+01, -2.0666e+01, -6.5055e+00,  ..., -2.0109e+01,\n",
       "         -1.7419e+01, -1.8045e+01],\n",
       "        ...,\n",
       "        [-2.3692e+01, -2.0684e+01, -4.8673e-01,  ..., -2.0376e+01,\n",
       "         -2.0961e+01, -2.1636e+01],\n",
       "        [-2.2985e+01, -2.0811e+01, -1.0160e+00,  ..., -1.8766e+01,\n",
       "         -1.8370e+01, -1.9378e+01],\n",
       "        [-2.3298e+01, -2.0915e+01, -9.6617e-01,  ..., -1.9531e+01,\n",
       "         -1.9013e+01, -1.9938e+01]], device='cuda:0'), tensor([[-2.3219e+01, -2.0116e+01, -1.0261e+00,  ..., -1.9723e+01,\n",
       "         -1.8911e+01, -1.9851e+01],\n",
       "        [-1.9737e+01, -1.9855e+01, -4.8663e+00,  ..., -1.4910e+01,\n",
       "         -1.4094e+01, -1.3441e+01],\n",
       "        [-2.2712e+01, -1.9727e+01, -1.0676e+00,  ..., -1.9234e+01,\n",
       "         -1.8275e+01, -1.9094e+01],\n",
       "        ...,\n",
       "        [-2.7919e+01, -2.5277e+01, -7.0547e-04,  ..., -2.4350e+01,\n",
       "         -2.5613e+01, -2.6025e+01],\n",
       "        [-2.7456e+01, -2.4169e+01, -8.3364e-04,  ..., -2.4156e+01,\n",
       "         -2.4911e+01, -2.6285e+01],\n",
       "        [-2.7772e+01, -2.4431e+01, -4.8935e-04,  ..., -2.4742e+01,\n",
       "         -2.5356e+01, -2.6616e+01]], device='cuda:0'), tensor([[-2.7983e+01, -2.4412e+01, -9.1249e-04,  ..., -2.4877e+01,\n",
       "         -2.5318e+01, -2.6956e+01],\n",
       "        [-2.8243e+01, -2.4903e+01, -5.3618e-04,  ..., -2.5672e+01,\n",
       "         -2.6074e+01, -2.7558e+01],\n",
       "        [-2.3694e+01, -2.3323e+01, -7.1006e+00,  ..., -2.0232e+01,\n",
       "         -1.7345e+01, -1.7899e+01],\n",
       "        ...,\n",
       "        [-2.3395e+01, -2.3067e+01, -7.1056e+00,  ..., -2.0290e+01,\n",
       "         -1.7413e+01, -1.7654e+01],\n",
       "        [-2.2952e+01, -2.3354e+01, -7.8933e+00,  ..., -1.7707e+01,\n",
       "         -1.7528e+01, -1.7645e+01],\n",
       "        [-2.1686e+01, -2.2389e+01, -5.5491e+00,  ..., -1.7815e+01,\n",
       "         -1.6467e+01, -1.7253e+01]], device='cuda:0'), tensor([[-20.7668, -22.1340,  -6.7746,  ..., -18.1003, -17.2526, -17.0278],\n",
       "        [-24.3028, -23.4552, -10.0255,  ..., -23.0079, -20.7352, -20.4494],\n",
       "        [-20.3330, -21.2783,  -7.2217,  ..., -17.7578, -17.7615, -17.1542],\n",
       "        ...,\n",
       "        [-20.8918, -22.2551,  -6.7863,  ..., -18.2844, -17.5314, -17.2582],\n",
       "        [-19.7013, -20.9943,  -6.3380,  ..., -15.6056, -14.7599, -13.7814],\n",
       "        [-25.0319, -21.4028,  -0.6335,  ..., -20.6322, -20.5822, -21.0086]],\n",
       "       device='cuda:0')), beam_indices=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  2,  2,  2,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  0,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  2,  2,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  2,  3,  7,  4,  4,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  1,  1,  6,  6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  2,  5,  5,  3,  4,  3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "        [ 0,  0,  0,  2,  3,  5,  7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n",
       "       device='cuda:0'), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\\n\\n∀ n m : nat, 0 + S n * m = S n * m\\n<TACTIC>\\n\\n  intros n m. </s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Theorem mult_0_plus : ∀ n m : nat, 0 + (S n * m) = S n * m.<THM-SEP>\\n\\n∀ n m : nat, 0 + S n * m = S n * m\\n<TACTIC>\\n\\n  intros n m.</s></s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         ...,\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577],\n",
       "         [-19.2553, -22.7084,  -6.9077,  ..., -15.1057, -14.6581, -15.3577]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-16.2049, -20.7909,  -7.4159,  ..., -14.8990, -13.2792, -15.3717],\n",
       "         [-19.4558, -20.5789,  -4.5457,  ..., -16.8198, -17.0659, -17.9211],\n",
       "         [-20.5151, -24.3491, -11.3335,  ..., -20.2546, -18.9214, -20.8530],\n",
       "         ...,\n",
       "         [-25.2098, -24.3875, -10.0008,  ..., -24.1531, -21.9400, -22.8440],\n",
       "         [-24.5632, -25.1726,  -7.6961,  ..., -20.4256, -18.5867, -20.0496],\n",
       "         [-24.8365, -25.4459, -13.8365,  ..., -20.8380, -18.9830, -20.7667]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-17.8605, -20.5812,  -6.2179,  ..., -15.1036, -15.2176, -15.8575],\n",
       "         [-20.9339, -24.5803, -11.7014,  ..., -20.5010, -19.1961, -21.1526],\n",
       "         [-17.5884, -20.4731,  -7.2036,  ..., -14.8584, -14.9861, -15.1826],\n",
       "         ...,\n",
       "         [-20.3710, -20.0585,  -5.4433,  ..., -19.5995, -15.7421, -16.9439],\n",
       "         [-19.8429, -19.5929,  -5.4484,  ..., -19.8722, -16.1720, -17.2623],\n",
       "         [-16.9641, -19.9905,  -7.2835,  ..., -14.7600, -14.5156, -14.8791]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-20.2881, -20.0440,  -5.5225,  ..., -20.2783, -16.6709, -17.6517],\n",
       "         [-20.1257, -19.3893,  -5.6257,  ..., -20.3483, -16.6833, -17.2773],\n",
       "         [-19.7866, -22.0952,  -7.1889,  ..., -15.0586, -15.9135, -14.8051],\n",
       "         ...,\n",
       "         [-21.1521, -20.2204,  -5.6638,  ..., -20.1872, -15.9568, -17.8618],\n",
       "         [-16.9696, -19.3524,  -4.6415,  ..., -14.9755, -15.0023, -15.5814],\n",
       "         [-21.0157, -20.4923,  -5.4083,  ..., -19.8849, -16.0030, -17.2936]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-21.8491, -20.7573,  -5.5873,  ..., -20.1010, -15.5873, -18.0767],\n",
       "         [-22.3323, -19.7429,  -1.3537,  ..., -18.7772, -18.2810, -18.7711],\n",
       "         [-21.2226, -20.1503,  -5.5917,  ..., -19.9784, -15.7226, -17.7076],\n",
       "         ...,\n",
       "         [-19.7414, -22.1516,  -6.9485,  ..., -18.3801, -16.8508, -17.4660],\n",
       "         [-20.9292, -20.0854,  -6.1694,  ..., -19.6792, -16.5371, -18.1328],\n",
       "         [-20.0020, -22.0997,  -7.1192,  ..., -18.0245, -16.8429, -16.9234]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-2.2181e+01, -2.0531e+01, -6.2786e+00,  ..., -2.0128e+01,\n",
       "          -1.7227e+01, -1.7959e+01],\n",
       "         [-2.7218e+01, -2.3895e+01, -8.6115e-04,  ..., -2.4513e+01,\n",
       "          -2.5018e+01, -2.6190e+01],\n",
       "         [-2.1836e+01, -2.0666e+01, -6.5055e+00,  ..., -2.0109e+01,\n",
       "          -1.7419e+01, -1.8045e+01],\n",
       "         ...,\n",
       "         [-2.3692e+01, -2.0684e+01, -4.8673e-01,  ..., -2.0376e+01,\n",
       "          -2.0961e+01, -2.1636e+01],\n",
       "         [-2.2985e+01, -2.0811e+01, -1.0160e+00,  ..., -1.8766e+01,\n",
       "          -1.8370e+01, -1.9378e+01],\n",
       "         [-2.3298e+01, -2.0915e+01, -9.6617e-01,  ..., -1.9531e+01,\n",
       "          -1.9013e+01, -1.9938e+01]], device='cuda:0'),\n",
       " tensor([[-2.3219e+01, -2.0116e+01, -1.0261e+00,  ..., -1.9723e+01,\n",
       "          -1.8911e+01, -1.9851e+01],\n",
       "         [-1.9737e+01, -1.9855e+01, -4.8663e+00,  ..., -1.4910e+01,\n",
       "          -1.4094e+01, -1.3441e+01],\n",
       "         [-2.2712e+01, -1.9727e+01, -1.0676e+00,  ..., -1.9234e+01,\n",
       "          -1.8275e+01, -1.9094e+01],\n",
       "         ...,\n",
       "         [-2.7919e+01, -2.5277e+01, -7.0547e-04,  ..., -2.4350e+01,\n",
       "          -2.5613e+01, -2.6025e+01],\n",
       "         [-2.7456e+01, -2.4169e+01, -8.3364e-04,  ..., -2.4156e+01,\n",
       "          -2.4911e+01, -2.6285e+01],\n",
       "         [-2.7772e+01, -2.4431e+01, -4.8935e-04,  ..., -2.4742e+01,\n",
       "          -2.5356e+01, -2.6616e+01]], device='cuda:0'),\n",
       " tensor([[-2.7983e+01, -2.4412e+01, -9.1249e-04,  ..., -2.4877e+01,\n",
       "          -2.5318e+01, -2.6956e+01],\n",
       "         [-2.8243e+01, -2.4903e+01, -5.3618e-04,  ..., -2.5672e+01,\n",
       "          -2.6074e+01, -2.7558e+01],\n",
       "         [-2.3694e+01, -2.3323e+01, -7.1006e+00,  ..., -2.0232e+01,\n",
       "          -1.7345e+01, -1.7899e+01],\n",
       "         ...,\n",
       "         [-2.3395e+01, -2.3067e+01, -7.1056e+00,  ..., -2.0290e+01,\n",
       "          -1.7413e+01, -1.7654e+01],\n",
       "         [-2.2952e+01, -2.3354e+01, -7.8933e+00,  ..., -1.7707e+01,\n",
       "          -1.7528e+01, -1.7645e+01],\n",
       "         [-2.1686e+01, -2.2389e+01, -5.5491e+00,  ..., -1.7815e+01,\n",
       "          -1.6467e+01, -1.7253e+01]], device='cuda:0'),\n",
       " tensor([[-20.7668, -22.1340,  -6.7746,  ..., -18.1003, -17.2526, -17.0278],\n",
       "         [-24.3028, -23.4552, -10.0255,  ..., -23.0079, -20.7352, -20.4494],\n",
       "         [-20.3330, -21.2783,  -7.2217,  ..., -17.7578, -17.7615, -17.1542],\n",
       "         ...,\n",
       "         [-20.8918, -22.2551,  -6.7863,  ..., -18.2844, -17.5314, -17.2582],\n",
       "         [-19.7013, -20.9943,  -6.3380,  ..., -15.6056, -14.7599, -13.7814],\n",
       "         [-25.0319, -21.4028,  -0.6335,  ..., -20.6322, -20.5822, -21.0086]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
