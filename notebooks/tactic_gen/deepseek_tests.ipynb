{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_brun_umass_edu/kthompson/coq-modeling/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tactic_gen.tactic_data import TEST_LM_EXAMPLE, example_collator_from_conf, ExampleCollator\n",
    "from tactic_gen.train_decoder import get_model, get_tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from util.constants import TRAINING_CONF_NAME\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(os.curdir).resolve().name == \"tactic_gen\":\n",
    "    os.chdir(\"../..\")\n",
    "elif Path(os.curdir).resolve().name == \"coq-modeling\": \n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f\"In an unexpected directory: {os.curdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_conf(checkpoint_loc: Path) -> Any:\n",
    "    training_conf_loc = checkpoint_loc.parent / TRAINING_CONF_NAME\n",
    "    with training_conf_loc.open('r') as f:\n",
    "        training_conf = yaml.safe_load(f)\n",
    "    return training_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_collator(checkpoint_loc: Path) -> ExampleCollator:\n",
    "    training_conf = get_training_conf(checkpoint_loc)\n",
    "    example_collator_conf = training_conf['example_collator']\n",
    "    example_collator = example_collator_from_conf(example_collator_conf) \n",
    "    return example_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_LOC = Path(\"models/deepseek-1.3b-basic/checkpoint-48000\")\n",
    "training_conf = get_training_conf(CHECKPOINT_LOC)\n",
    "example_collator = get_example_collator(CHECKPOINT_LOC)\n",
    "tokenizer = get_tokenizer(training_conf, add_eos=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(str(CHECKPOINT_LOC))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "BEAM = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_brun_umass_edu/kthompson/coq-modeling/venv/lib/python3.12/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "collated_input = example_collator.collate_input(tokenizer, TEST_LM_EXAMPLE)\n",
    "inputs = tokenizer(collated_input, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=64, \n",
    "        do_sample=not BEAM, \n",
    "        temperature=None if BEAM else 1.0,\n",
    "        num_beams=(),\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        num_return_sequences=64, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_out = out.sequences[:, inputs[\"input_ids\"].shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_out == -torch.inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22698,   284,    13,  ..., 32021, 32021, 32021],\n",
       "        [  185,   207, 22698,  ..., 32021, 32021, 32021],\n",
       "        [  185,   207, 22698,  ..., 32021, 32021, 32021],\n",
       "        ...,\n",
       "        [22698,   284,    13,  ..., 32021, 32021, 32021],\n",
       "        [22698,   284,    13,  ..., 32021, 32021, 32021],\n",
       "        [22698,   284,    13,  ..., 32021, 32021, 32021]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.compute_transition_scores(gen_out, out.scores, normalize_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0525, -0.0125, -0.2690,  ...,    -inf,    -inf,    -inf],\n",
       "        [-0.7967, -0.0052, -0.1003,  ...,    -inf,    -inf,    -inf],\n",
       "        [-0.7946, -0.0052, -0.0786,  ...,    -inf,    -inf,    -inf],\n",
       "        ...,\n",
       "        [-1.0528, -0.0119, -0.1985,  ...,    -inf,    -inf,    -inf],\n",
       "        [-1.0960, -0.0064, -0.1984,  ...,    -inf,    -inf,    -inf],\n",
       "        [-1.1107, -0.0103, -0.2682,  ...,    -inf,    -inf,    -inf]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.3340169191360474,\n",
       " -1.1784601211547852,\n",
       " -1.1543546915054321,\n",
       " -0.9947277307510376,\n",
       " -6.49794340133667,\n",
       " -0.9908392429351807,\n",
       " -8.996271133422852,\n",
       " -1.3592931032180786,\n",
       " -6.107923984527588,\n",
       " -4.414965629577637,\n",
       " -6.603355884552002,\n",
       " -1.0965176820755005,\n",
       " -5.465126991271973,\n",
       " -1.0972161293029785,\n",
       " -0.9893094301223755,\n",
       " -9.866199493408203,\n",
       " -1.344957947731018,\n",
       " -1.120327353477478,\n",
       " -3.602762460708618,\n",
       " -1.3293654918670654,\n",
       " -3.1278340816497803,\n",
       " -9.600914001464844,\n",
       " -0.9180083870887756,\n",
       " -0.9945132732391357,\n",
       " -1.6933228969573975,\n",
       " -6.059633255004883,\n",
       " -8.38379192352295,\n",
       " -1.3060755729675293,\n",
       " -7.074195384979248,\n",
       " -1.3598614931106567,\n",
       " -1.0195387601852417,\n",
       " -1.1817296743392944,\n",
       " -11.261676788330078,\n",
       " -0.9186042547225952,\n",
       " -1.170425295829773,\n",
       " -1.260474443435669,\n",
       " -0.9372342228889465,\n",
       " -1.0401631593704224,\n",
       " -1.1500436067581177,\n",
       " -1.3038089275360107,\n",
       " -0.9233178496360779,\n",
       " -1.057296633720398,\n",
       " -1.0779473781585693,\n",
       " -1.2862298488616943,\n",
       " -0.8998291492462158,\n",
       " -6.451598167419434,\n",
       " -9.283773422241211,\n",
       " -19.630115509033203,\n",
       " -1.1519118547439575,\n",
       " -1.0825247764587402,\n",
       " -1.0212440490722656,\n",
       " -0.8017032742500305,\n",
       " -1.365057110786438,\n",
       " -0.9178531169891357,\n",
       " -6.778486251831055,\n",
       " -10.172578811645508,\n",
       " -1.1647636890411377,\n",
       " -8.890254974365234,\n",
       " -1.3291651010513306,\n",
       " -20.979352951049805,\n",
       " -0.9883596897125244,\n",
       " -1.2632825374603271,\n",
       " -1.3008735179901123,\n",
       " -1.389192819595337]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores != -torch.inf).sum(axis=1).tolist()\n",
    "scores.where(scores != -torch.inf, torch.tensor(0.0)).sum(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  generalize dependent x.',\n",
       " '\\n  induction l.',\n",
       " \"\\n  induction l as [|l' H].\",\n",
       " ' induction l.',\n",
       " ' induction l as [|h t IH].',\n",
       " '\\n  simpl.',\n",
       " '\\n  induction l as [| h t IH].',\n",
       " '\\n  induction l.',\n",
       " \"\\n  induction l as [|y l'].\",\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " \"\\n  induction l as [|x0 l' IHl'].\",\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " ' simpl.',\n",
       " ' induction l.',\n",
       " ' simpl.',\n",
       " '\\n  rewrite (rev_involutive l).',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l as [|h t].',\n",
       " \"\\n  induction l as [ | y l'].\",\n",
       " ' induction l.',\n",
       " '\\n  rewrite app_comm.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  simpl.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l as [|h t IHl].',\n",
       " '\\n  induction l as [|y t].',\n",
       " \"\\n  induction l as [|l' x' IH]; auto.\",\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " \"\\n  induction l as [|h t IHl'].\",\n",
       " '\\n  induction l as [|h1 t1 IHt1].',\n",
       " '\\n  induction l.',\n",
       " ' rewrite rev_app_rev.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " ' induction l.']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_num_tokens = inputs[\"input_ids\"].shape[1]\n",
    "tokenizer.batch_decode(out.sequences[:, input_num_tokens:], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_deployment.model_wrapper import DecoderLocalWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_LOC = Path(\"models/deepseek-1.3b-basic/checkpoint-48000\")\n",
    "model_wrapper = DecoderLocalWrapper.from_checkpoint(CHECKPOINT_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_brun_umass_edu/kthompson/coq-modeling/venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:554: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collated:  \n",
      "[STATE]\n",
      "x: X\n",
      "l: list X\n",
      "\n",
      "rev l ++ [x] = rev (x :: l)\n",
      "[SCRIPT]\n",
      "Theorem rev_app : forall x l, rev l ++ [x] = rev (x::l).\n",
      "Proof.\n",
      "  intros.\n",
      "[TACTIC]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_brun_umass_edu/kthompson/coq-modeling/venv/lib/python3.12/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "result = model_wrapper.get_recs(TEST_LM_EXAMPLE, 64, \"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n  induction l.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " ' induction l as [|h t IH].',\n",
       " ' induction l.',\n",
       " \"\\n  induction l as [ | y0 l' IHl'].\",\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " ' induction l as [|h t].',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l as [|h t].',\n",
       " \"\\n  induction l as [|h t I'].\",\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l as [|m l IHl].',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  rewrite rev_app_split.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l; simpl.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " ' induction l.',\n",
       " ' unfold rev.',\n",
       " ' induction l.',\n",
       " '\\n  revert x.',\n",
       " '\\n  induction l; auto.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' \\n  rewrite <- rev_involutive.',\n",
       " ' symmetry.',\n",
       " ' simpl.',\n",
       " ' induction l; simpl; auto.',\n",
       " '\\n  induction l.',\n",
       " ' simpl.',\n",
       " \" induction l as [| n l' IH].\",\n",
       " '\\n  induction l.',\n",
       " '\\n  elim l; intros.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " ' rewrite rev_involutive.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.',\n",
       " '\\n  induction l.',\n",
       " '\\n  induction l.',\n",
       " ' simpl.',\n",
       " ' induction l as [|y ys IH].',\n",
       " ' induction l.',\n",
       " ' simpl.',\n",
       " '\\n  induction l.',\n",
       " ' induction l.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.next_tactic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.091173529624939,\n",
       " -1.0829819440841675,\n",
       " -0.9765117168426514,\n",
       " -5.801501274108887,\n",
       " -1.3765190839767456,\n",
       " -13.580381393432617,\n",
       " -1.2010478973388672,\n",
       " -0.7581014633178711,\n",
       " -0.9752275943756104,\n",
       " -1.3491300344467163,\n",
       " -6.818093299865723,\n",
       " -0.9610227346420288,\n",
       " -1.306260347366333,\n",
       " -0.969602108001709,\n",
       " -7.681689739227295,\n",
       " -6.0971221923828125,\n",
       " -9.352446556091309,\n",
       " -0.9166039228439331,\n",
       " -0.9867836236953735,\n",
       " -10.54260540008545,\n",
       " -1.3574259281158447,\n",
       " -1.7184215784072876,\n",
       " -0.9940738677978516,\n",
       " -11.772241592407227,\n",
       " -1.07068932056427,\n",
       " -1.2064350843429565,\n",
       " -1.4584046602249146,\n",
       " -1.0888279676437378,\n",
       " -3.8191006183624268,\n",
       " -1.2318209409713745,\n",
       " -1.3284974098205566,\n",
       " -1.3770112991333008,\n",
       " -4.765250205993652,\n",
       " -1.0577272176742554,\n",
       " -8.313982009887695,\n",
       " -6.794739246368408,\n",
       " -1.26614511013031,\n",
       " -0.9316457509994507,\n",
       " -1.3570245504379272,\n",
       " -0.9584465026855469,\n",
       " -1.2043745517730713,\n",
       " -10.348194122314453,\n",
       " -7.571715354919434,\n",
       " -10.32215690612793,\n",
       " -5.461085796356201,\n",
       " -0.9433013796806335,\n",
       " -3.6149213314056396,\n",
       " -8.61722183227539,\n",
       " -0.9480211734771729,\n",
       " -10.675844192504883,\n",
       " -0.9374567866325378,\n",
       " -1.2903416156768799,\n",
       " -6.581651210784912,\n",
       " -0.9620234966278076,\n",
       " -1.1556146144866943,\n",
       " -1.3003675937652588,\n",
       " -0.9509530067443848,\n",
       " -1.3029683828353882,\n",
       " -3.599736452102661,\n",
       " -9.22715950012207,\n",
       " -1.0112096071243286,\n",
       " -3.33099365234375,\n",
       " -0.9744158983230591,\n",
       " -1.3073242902755737]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 16,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 11,\n",
       " 12,\n",
       " 6,\n",
       " 4,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 14,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 12,\n",
       " 6,\n",
       " 10,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 12,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.num_tokens_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
