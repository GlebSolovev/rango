# File Paths
data_path: "data/whole-proof-ret"
model_name: "google-t5/t5-small"
  #model_name: "google-t5/t5-base"
output_dir: "models/t5-fid-small-whole-proof-ret" 

# Training Args
max_encode_len: 448 
max_decode_len: 64 
max_num_passages: 8
per_device_train_batch_size: 4
learning_rate: 1.0e-3
num_train_epochs: 50
max_steps: 130000

# Evaluation Args
eval_steps: 500 
save_steps: 500
eval_accumulation_steps: 1
per_device_eval_batch_size: 2
num_eval_examples: 2000 # Evaluation would take ~2 hours each time w/o limiting this

# Logging Args
logging_steps: 10
save_total_limit: 2

# Train from checkpoint
#checkpoint_name: "/home/ubuntu/coq-modeling/models/codellama-7b-tpe-1k/checkpoint-15700"
